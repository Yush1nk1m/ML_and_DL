{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 22:08:48.387093: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-15 22:08:48.393284: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-15 22:08:48.474895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 22:08:48.474970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 22:08:48.477032: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 22:08:48.490127: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-15 22:08:48.491633: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-15 22:08:50.145838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model 'sequential_1' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3454\u001b[0m, in \u001b[0;36mModel.weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3444\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mweights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3446\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the list of all layer variables/weights.\u001b[39;00m\n\u001b[1;32m   3447\u001b[0m \n\u001b[1;32m   3448\u001b[0m \u001b[38;5;124;03m    Note: This will not track the weights of nested `tf.Modules` that are\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3452\u001b[0m \u001b[38;5;124;03m      A list of variables.\u001b[39;00m\n\u001b[1;32m   3453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dedup_weights(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_undeduplicated_weights\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3459\u001b[0m, in \u001b[0;36mModel._undeduplicated_weights\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_undeduplicated_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3458\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the undeduplicated list of all layer variables/weights.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3459\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3460\u001b[0m     weights \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   3461\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_tracked_trackables:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/sequential.py:509\u001b[0m, in \u001b[0;36mSequential._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;66;03m# When the graph has not been initialized, use the Model's\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;66;03m# implementation to to check if the weights has been created.\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_weights_created\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:3838\u001b[0m, in \u001b[0;36mModel._assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   3829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3830\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m   3831\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;241m!=\u001b[39m Model\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3836\u001b[0m     \u001b[38;5;66;03m# Also make sure to exclude Model class itself which has build()\u001b[39;00m\n\u001b[1;32m   3837\u001b[0m     \u001b[38;5;66;03m# defined.\u001b[39;00m\n\u001b[0;32m-> 3838\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3839\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights for model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m have not yet been \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights are created when the model is first called on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs or `build()` is called with an `input_shape`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3843\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model 'sequential_1' have not yet been created. Weights are created when the model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(input_shape=(None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[ 0.14485991, -0.19207734,  0.00301257,  0.00564203, -0.2003037 ,\n",
       "         -0.04069087, -0.03673145,  0.26229954,  0.24616188,  0.01581174,\n",
       "          0.03658161, -0.23985785,  0.20763212, -0.26009455,  0.2257452 ,\n",
       "          0.11073321, -0.08046149, -0.18871516,  0.15010571, -0.01123828,\n",
       "         -0.04747885,  0.07035956, -0.29411757,  0.06580359,  0.05810371,\n",
       "          0.04807761,  0.15823182,  0.27975678,  0.26390153,  0.2547136 ,\n",
       "          0.03526282,  0.1512323 , -0.29281834,  0.26212013, -0.04602501,\n",
       "          0.1381245 ,  0.01172844, -0.00502366,  0.15327391,  0.2831776 ,\n",
       "          0.12493163, -0.11012411, -0.24750252,  0.26392227, -0.28758195,\n",
       "         -0.24903813, -0.22205153,  0.07197079, -0.10868582,  0.22222328,\n",
       "         -0.03826797, -0.2881966 ,  0.05050641,  0.04949784,  0.12121606,\n",
       "          0.21703112, -0.11255813,  0.06947249, -0.17784923,  0.00337023,\n",
       "          0.03825685, -0.2860621 ,  0.24071282,  0.07545254],\n",
       "        [ 0.0132727 , -0.08072604,  0.21542788,  0.10270876, -0.16740084,\n",
       "         -0.12371565,  0.18598306, -0.22164258, -0.00836241,  0.1760208 ,\n",
       "          0.12860104,  0.20032847, -0.16698438, -0.13637619,  0.2598145 ,\n",
       "         -0.18360376, -0.21389788, -0.21184963, -0.08947837, -0.17701876,\n",
       "          0.04643178,  0.00068694,  0.25474143,  0.09727186, -0.0943014 ,\n",
       "         -0.1811549 ,  0.07483554,  0.14699018,  0.15854234, -0.05522305,\n",
       "         -0.04871851, -0.22224703,  0.24921536,  0.01723146, -0.00068259,\n",
       "          0.12108079,  0.25501966,  0.20947456, -0.28061342,  0.2848066 ,\n",
       "         -0.2484929 , -0.08790645, -0.03545246, -0.17559594,  0.15264219,\n",
       "         -0.14418367, -0.07906744, -0.16930538,  0.01421461, -0.12966846,\n",
       "          0.00444552, -0.12537484,  0.1466229 , -0.13222833, -0.11219049,\n",
       "          0.07567564, -0.225974  , -0.01597619, -0.27952638, -0.09258656,\n",
       "          0.22241515, -0.10961655, -0.11861874,  0.15685233],\n",
       "        [ 0.18030167, -0.13637862,  0.26156032,  0.04191732, -0.23272304,\n",
       "         -0.07767452, -0.2073611 , -0.07973981, -0.071348  , -0.25154722,\n",
       "          0.00701988, -0.01393101,  0.01495677,  0.24909413, -0.11110786,\n",
       "          0.03529328,  0.02598217, -0.257186  , -0.25074634,  0.28392315,\n",
       "          0.17433694,  0.07332197,  0.06012812,  0.06238475,  0.13548607,\n",
       "          0.2511996 ,  0.08958375, -0.27988747, -0.24462636, -0.1366812 ,\n",
       "          0.11405835, -0.1409044 ,  0.19058281, -0.03226766,  0.07422659,\n",
       "         -0.076308  ,  0.11622289,  0.27200556,  0.20120108,  0.1875714 ,\n",
       "         -0.24810255,  0.2748646 ,  0.21017855, -0.24303353, -0.1748772 ,\n",
       "         -0.26031232,  0.08411178,  0.0137513 , -0.2537322 , -0.23081471,\n",
       "         -0.18516141, -0.16476661,  0.20771939, -0.12544434, -0.23153326,\n",
       "         -0.22578172,  0.10532594, -0.01054808, -0.08502188, -0.0299114 ,\n",
       "         -0.06296811,  0.2678321 ,  0.18242383,  0.00199965]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[-2.33472541e-01, -1.67565435e-01,  2.51195759e-01,\n",
       "         -2.51609236e-01, -1.34962454e-01,  2.50928432e-01,\n",
       "          1.17841154e-01, -5.71492910e-02,  2.18058378e-01,\n",
       "         -1.25202373e-01],\n",
       "        [-1.64830863e-01,  2.51925081e-01,  5.61269522e-02,\n",
       "         -5.75117469e-02, -1.66656733e-01,  9.38345194e-02,\n",
       "         -1.27152964e-01,  7.73004591e-02, -4.49228287e-03,\n",
       "         -1.28186166e-01],\n",
       "        [-1.49249032e-01,  1.78885043e-01, -6.00348413e-02,\n",
       "          2.15201885e-01, -1.72298729e-01, -2.13501140e-01,\n",
       "          2.06740946e-01,  2.27775484e-01,  1.43854827e-01,\n",
       "         -1.99880213e-01],\n",
       "        [ 1.90368295e-02,  4.67647016e-02, -1.17293105e-01,\n",
       "         -2.43452102e-01,  6.91061020e-02, -1.86152905e-01,\n",
       "          1.54351294e-02,  7.15333521e-02,  2.62209982e-01,\n",
       "         -2.74532408e-01],\n",
       "        [-1.09374583e-01, -3.38518023e-02, -4.67383713e-02,\n",
       "         -2.84030497e-01,  7.00313151e-02, -2.09113955e-02,\n",
       "          2.75772065e-01,  1.16080135e-01,  2.25689024e-01,\n",
       "         -1.99160933e-01],\n",
       "        [ 8.34921002e-03,  6.89110756e-02, -1.27362475e-01,\n",
       "         -2.47061849e-02, -1.94720447e-01, -2.52646804e-01,\n",
       "         -1.61810741e-01,  2.56940871e-01, -1.86427921e-01,\n",
       "          1.56722724e-01],\n",
       "        [-7.10657388e-02, -2.50906169e-01,  1.68730915e-02,\n",
       "          2.47251183e-01, -1.16239458e-01,  2.41591960e-01,\n",
       "          4.84743416e-02,  2.03470528e-01, -6.00617975e-02,\n",
       "          2.41051018e-02],\n",
       "        [ 9.02189314e-02,  1.44342005e-01, -2.62377053e-01,\n",
       "         -6.83975518e-02, -5.39887846e-02,  1.41411036e-01,\n",
       "         -6.64139092e-02,  1.54444724e-01,  2.72379309e-01,\n",
       "          8.63873959e-03],\n",
       "        [-4.90274429e-02, -2.66160727e-01,  8.04850757e-02,\n",
       "          1.89799994e-01, -2.30608165e-01,  1.30163103e-01,\n",
       "         -3.28133702e-02,  2.42699832e-01,  1.18497312e-01,\n",
       "          1.84054315e-01],\n",
       "        [-2.55050600e-01,  1.58901632e-01, -4.56996560e-02,\n",
       "          2.77499408e-01, -1.54620886e-01,  1.93976462e-01,\n",
       "         -2.68511921e-01,  7.39483833e-02, -1.19329706e-01,\n",
       "          7.16095269e-02],\n",
       "        [-2.10348994e-01, -2.34803990e-01, -2.55195349e-01,\n",
       "          7.99467862e-02,  1.85244501e-01,  4.94092703e-02,\n",
       "         -7.81916380e-02, -5.32504916e-02,  1.04728043e-01,\n",
       "         -7.02532381e-02],\n",
       "        [ 6.68028295e-02,  1.04095995e-01,  2.09808797e-01,\n",
       "         -2.71489739e-01, -2.71581948e-01,  1.64241791e-01,\n",
       "          1.26882493e-01,  2.41198033e-01, -8.95082951e-03,\n",
       "         -5.83107322e-02],\n",
       "        [-1.39382303e-01,  2.32255012e-01, -6.11775517e-02,\n",
       "          2.50862807e-01, -1.64444566e-01, -1.48952886e-01,\n",
       "          4.01922166e-02, -7.93346912e-02, -7.89877772e-02,\n",
       "          9.06938314e-02],\n",
       "        [ 2.24711508e-01, -2.78068542e-01,  1.69144928e-01,\n",
       "         -1.84950262e-01, -2.09131867e-01, -2.54908592e-01,\n",
       "          2.16230839e-01,  4.66725826e-02, -8.86700451e-02,\n",
       "         -2.76998669e-01],\n",
       "        [-1.69861108e-01,  1.26728535e-01,  5.67918420e-02,\n",
       "         -2.30419502e-01,  1.80715948e-01, -1.28916800e-01,\n",
       "         -1.06757805e-01,  7.80242682e-03, -1.23000801e-01,\n",
       "         -2.52886981e-01],\n",
       "        [ 2.19151348e-01, -2.13148803e-01, -2.17554525e-01,\n",
       "         -2.53873289e-01, -1.93031222e-01, -5.22425771e-03,\n",
       "         -1.25509977e-01, -1.69965029e-01,  5.62103093e-02,\n",
       "         -2.01474041e-01],\n",
       "        [ 3.60080302e-02, -2.27584317e-01, -1.39579311e-01,\n",
       "         -1.68555185e-01, -1.18376881e-01,  2.70739049e-01,\n",
       "         -1.48728862e-01, -1.75575584e-01,  2.36145705e-01,\n",
       "          1.09851986e-01],\n",
       "        [-1.68027610e-01,  1.12182468e-01, -1.70720518e-02,\n",
       "          3.09962332e-02,  2.15142220e-01,  1.86941177e-01,\n",
       "          2.14731097e-02, -1.48841217e-01, -1.88385651e-01,\n",
       "          4.26650941e-02],\n",
       "        [-5.88779449e-02, -1.69431224e-01, -1.30495623e-01,\n",
       "         -1.49986163e-01,  3.66283357e-02,  1.80426747e-01,\n",
       "         -6.45720810e-02,  2.31249928e-02,  1.89886123e-01,\n",
       "          1.88621849e-01],\n",
       "        [ 4.28729653e-02,  2.83237725e-01,  4.49051559e-02,\n",
       "         -2.19309181e-01,  2.27487773e-01, -1.20687753e-01,\n",
       "          1.92292392e-01,  5.63901663e-03, -1.34652883e-01,\n",
       "          1.00634336e-01],\n",
       "        [-2.55888700e-02,  1.34532839e-01,  9.25114155e-02,\n",
       "         -1.98687941e-01, -6.92671537e-03, -8.51658881e-02,\n",
       "          2.42863625e-01,  4.91609871e-02,  2.23040372e-01,\n",
       "          1.88471943e-01],\n",
       "        [ 8.42669606e-02, -1.42129436e-01, -1.16429955e-01,\n",
       "         -1.83337077e-01,  1.66804254e-01,  2.29465634e-01,\n",
       "         -2.29164913e-01,  7.82008171e-02, -1.08760893e-02,\n",
       "         -2.51263678e-01],\n",
       "        [ 1.44349068e-01,  1.48351520e-01, -4.29648161e-03,\n",
       "         -1.96488887e-01,  2.52416998e-01, -5.77467829e-02,\n",
       "          9.19698775e-02,  3.67462337e-02, -1.32360876e-01,\n",
       "          1.24497771e-01],\n",
       "        [ 4.05411720e-02, -2.66763926e-01, -6.18910789e-03,\n",
       "         -2.17743322e-01,  1.94711983e-02,  3.98929119e-02,\n",
       "          1.84165120e-01, -2.64904708e-01,  2.15062112e-01,\n",
       "          8.64085257e-02],\n",
       "        [-2.43470773e-01,  9.00107324e-02,  9.48743522e-02,\n",
       "         -1.33065432e-01, -1.23150155e-01, -1.75888419e-01,\n",
       "         -1.09919325e-01, -1.21924624e-01, -2.61966050e-01,\n",
       "         -1.46763340e-01],\n",
       "        [ 2.47322708e-01, -2.06560642e-01,  1.88282132e-02,\n",
       "         -2.32817546e-01, -1.00674599e-01, -5.05455881e-02,\n",
       "         -1.01702377e-01,  6.60499632e-02, -2.57456452e-01,\n",
       "         -7.54990876e-02],\n",
       "        [ 2.65966624e-01,  1.93649352e-01,  2.83020407e-01,\n",
       "         -8.21588784e-02,  2.22657353e-01,  1.25738353e-01,\n",
       "         -3.54373455e-03,  2.26639301e-01, -1.60301626e-02,\n",
       "          1.58285946e-01],\n",
       "        [ 2.40834087e-01,  1.73979402e-02, -2.69881666e-01,\n",
       "         -1.84631109e-01, -2.82115251e-01,  2.02204198e-01,\n",
       "         -2.60125518e-01,  2.40495473e-01, -6.15494549e-02,\n",
       "         -7.96820819e-02],\n",
       "        [-2.54617959e-01,  3.61142159e-02,  2.52884239e-01,\n",
       "          1.54285103e-01,  2.61426419e-01, -2.04899311e-02,\n",
       "         -1.11805558e-01, -2.63641566e-01,  3.20333242e-03,\n",
       "          2.38976032e-01],\n",
       "        [ 1.07441097e-01,  1.93919361e-01,  2.35870093e-01,\n",
       "         -2.10232764e-01,  1.05553657e-01,  8.10535848e-02,\n",
       "          1.51344568e-01,  8.51566494e-02,  7.31205344e-02,\n",
       "         -1.15498990e-01],\n",
       "        [ 2.26621062e-01, -2.72083700e-01,  2.30829149e-01,\n",
       "         -2.31984749e-01,  2.00359523e-01, -2.62377322e-01,\n",
       "          3.59077454e-02, -1.33335561e-01,  2.68708467e-02,\n",
       "          2.70140797e-01],\n",
       "        [-5.70528805e-02, -7.35932440e-02, -1.38847470e-01,\n",
       "          2.79913038e-01,  2.88329720e-02,  1.50076151e-02,\n",
       "          1.27043724e-01, -2.05266804e-01,  1.78313076e-01,\n",
       "         -1.55800596e-01],\n",
       "        [ 2.60171980e-01,  2.78718919e-01,  2.62105614e-01,\n",
       "         -1.09976962e-01,  3.47031355e-02,  2.09929347e-01,\n",
       "          2.68548697e-01,  2.25221425e-01,  2.68578917e-01,\n",
       "          2.10279942e-01],\n",
       "        [ 1.07008219e-03,  4.21548486e-02, -3.09816599e-02,\n",
       "          1.63145721e-01,  2.12587208e-01, -2.81672895e-01,\n",
       "         -2.65736401e-01,  1.66798890e-01,  8.38852227e-02,\n",
       "         -2.60778964e-02],\n",
       "        [-4.78772670e-02,  8.37327540e-02,  2.55470484e-01,\n",
       "         -2.47972697e-01,  1.90650165e-01, -6.90581799e-02,\n",
       "         -1.50197566e-01,  1.20559573e-01,  8.51552188e-02,\n",
       "         -1.06155083e-01],\n",
       "        [ 5.53122759e-02, -4.04204726e-02, -3.62285972e-02,\n",
       "          2.34146088e-01, -1.41810417e-01,  4.03694808e-02,\n",
       "          1.59954190e-01,  1.24973714e-01,  1.16230756e-01,\n",
       "          1.75315291e-01],\n",
       "        [-2.11486876e-01, -1.58753976e-01,  2.37372071e-01,\n",
       "         -2.36916214e-01, -1.49225950e-01,  1.82772279e-02,\n",
       "          2.04375356e-01, -1.86822370e-01, -2.48680502e-01,\n",
       "         -8.83536190e-02],\n",
       "        [-2.38723636e-01,  9.40474868e-03,  4.29777801e-02,\n",
       "          1.56988174e-01, -1.48449838e-01,  1.66387141e-01,\n",
       "         -2.73273677e-01,  7.24815726e-02,  1.13950789e-01,\n",
       "          2.70508021e-01],\n",
       "        [-2.59428710e-01, -9.89052802e-02, -1.24603525e-01,\n",
       "          2.24631101e-01, -1.80965170e-01,  8.18998814e-02,\n",
       "         -9.21953917e-02, -2.51660436e-01,  2.34695405e-01,\n",
       "          2.64920264e-01],\n",
       "        [ 3.89177501e-02, -1.35890156e-01,  2.55553454e-01,\n",
       "         -2.29351133e-01,  7.68468976e-02,  9.10628736e-02,\n",
       "          2.83201069e-01,  4.51938808e-02,  2.00337708e-01,\n",
       "         -1.34838149e-01],\n",
       "        [-1.60357445e-01, -6.34088665e-02,  2.66601950e-01,\n",
       "          1.37347460e-01, -6.97949827e-02, -4.54412699e-02,\n",
       "         -1.86010346e-01,  5.21266460e-02, -1.57993272e-01,\n",
       "          3.87782454e-02],\n",
       "        [-9.84486938e-03,  1.65821970e-01,  1.44096434e-01,\n",
       "          5.28195202e-02,  2.07260221e-01, -1.64804578e-01,\n",
       "          1.19690478e-01,  2.71477401e-02,  2.82160729e-01,\n",
       "          2.78447360e-01],\n",
       "        [ 1.47120714e-01, -2.30242312e-02,  2.18466252e-01,\n",
       "         -6.79473132e-02, -7.32785761e-02,  1.72458529e-01,\n",
       "          2.13877439e-01, -2.70414442e-01, -5.92883378e-02,\n",
       "          2.11012453e-01],\n",
       "        [-5.60772568e-02, -2.06412643e-01,  1.99383497e-03,\n",
       "          2.54143268e-01, -3.05605233e-02,  1.73321009e-01,\n",
       "         -1.21167734e-01,  2.59537131e-01, -3.34610343e-02,\n",
       "         -1.66972220e-01],\n",
       "        [-2.12588102e-01,  5.58479130e-02,  1.85778707e-01,\n",
       "          1.14764512e-01, -1.38127238e-01, -5.52084744e-02,\n",
       "          3.51420343e-02,  1.94047391e-02, -1.53122306e-01,\n",
       "          8.51344466e-02],\n",
       "        [ 2.34418720e-01,  2.91219056e-02, -2.69642681e-01,\n",
       "         -2.11444303e-01,  1.09754980e-01,  3.18765640e-03,\n",
       "          2.15460032e-01, -2.37893075e-01, -2.24462509e-01,\n",
       "         -2.44596988e-01],\n",
       "        [ 1.94813371e-01,  8.24449658e-02, -8.58771652e-02,\n",
       "          1.82468444e-01, -1.22495636e-01, -2.08764181e-01,\n",
       "         -4.60633636e-03,  1.54988438e-01, -7.82406628e-02,\n",
       "         -1.16333619e-01],\n",
       "        [ 7.07560182e-02, -3.42213809e-02,  2.17058510e-01,\n",
       "         -2.64105439e-01, -1.16445646e-01,  2.47644395e-01,\n",
       "         -7.35064149e-02,  2.32786268e-01, -9.56017971e-02,\n",
       "         -2.28483975e-02],\n",
       "        [ 2.74846762e-01,  9.25211310e-02, -1.51046321e-01,\n",
       "          4.50665951e-02,  6.20298386e-02,  3.59983146e-02,\n",
       "          2.83032626e-01, -9.52932984e-02, -2.62203217e-02,\n",
       "         -1.24992728e-02],\n",
       "        [ 2.38933295e-01, -5.31470925e-02,  5.94801903e-02,\n",
       "          1.40564442e-02,  1.36334270e-01, -2.42495209e-01,\n",
       "         -1.80642292e-01, -1.50024861e-01,  5.19452393e-02,\n",
       "         -1.25176921e-01],\n",
       "        [ 1.13708556e-01,  5.81727922e-02,  1.43391907e-01,\n",
       "         -8.14733952e-02, -2.11672544e-01,  1.68779910e-01,\n",
       "          3.73945236e-02, -9.34886783e-02, -1.83287442e-01,\n",
       "          1.00634336e-01],\n",
       "        [-3.27562690e-02,  1.32717550e-01,  2.37447768e-01,\n",
       "         -1.84426561e-01,  1.25765324e-01, -4.49036658e-02,\n",
       "         -2.53346384e-01, -2.03647643e-01,  2.61748880e-01,\n",
       "          1.33923531e-01],\n",
       "        [ 3.24407220e-03, -1.85671449e-01, -2.47598827e-01,\n",
       "          2.12299496e-01,  2.10562348e-01, -2.17871770e-01,\n",
       "          1.43784493e-01,  1.69384509e-01,  2.12080151e-01,\n",
       "          3.49512696e-03],\n",
       "        [ 5.69999218e-04, -1.62110925e-02,  1.16452962e-01,\n",
       "         -2.07634911e-01,  1.75209522e-01, -1.61760747e-02,\n",
       "          9.06058252e-02,  1.46341801e-01, -1.46151245e-01,\n",
       "         -8.05377960e-04],\n",
       "        [-1.54992029e-01,  1.42643899e-01, -1.03040040e-02,\n",
       "         -7.15078264e-02, -7.02205896e-02,  8.99528861e-02,\n",
       "         -1.16619572e-01, -1.59565523e-01, -3.55921388e-02,\n",
       "          4.46258485e-02],\n",
       "        [-2.66392827e-01,  6.90560937e-02, -7.92141259e-02,\n",
       "          2.59307295e-01, -2.13692859e-01,  8.71272087e-02,\n",
       "          2.04140395e-01,  2.72198647e-01, -1.94364503e-01,\n",
       "         -5.25259823e-02],\n",
       "        [ 1.99787825e-01, -1.05642855e-01, -1.81130007e-01,\n",
       "          7.06890225e-02, -1.48376584e-01, -2.41535187e-01,\n",
       "         -1.91947177e-01,  1.97454005e-01, -2.76170671e-02,\n",
       "          1.20197803e-01],\n",
       "        [ 2.13087499e-01,  4.93400693e-02,  1.71292752e-01,\n",
       "          2.73626894e-01, -9.37057137e-02, -1.21563792e-01,\n",
       "          1.82911217e-01, -2.47698486e-01, -1.93575352e-01,\n",
       "         -2.37647653e-01],\n",
       "        [-2.02852741e-01,  4.92271781e-02,  2.47143358e-01,\n",
       "         -2.52187550e-02, -1.55029640e-01,  1.72442853e-01,\n",
       "         -9.34877992e-02,  8.01743567e-02, -2.15963125e-02,\n",
       "         -1.21969983e-01],\n",
       "        [-2.21820951e-01, -2.81726539e-01,  2.79267997e-01,\n",
       "          2.74249047e-01, -2.52702326e-01,  7.40337372e-03,\n",
       "         -2.82149404e-01, -2.55393177e-01, -2.38080323e-02,\n",
       "          4.32525873e-02],\n",
       "        [ 2.68398970e-01,  1.47340596e-01, -1.71284199e-01,\n",
       "          8.72959793e-02,  2.83503741e-01,  2.08290935e-01,\n",
       "          1.41456723e-01,  1.82537943e-01, -9.04357731e-02,\n",
       "          3.46889496e-02],\n",
       "        [-9.96700525e-02, -2.24270105e-01, -1.52757123e-01,\n",
       "          1.69574529e-01, -1.51336193e-04,  6.15132749e-02,\n",
       "         -1.34589672e-01, -9.24174637e-02, -8.91759545e-02,\n",
       "         -2.39972383e-01],\n",
       "        [-2.72229016e-02,  4.69383001e-02,  2.23035485e-01,\n",
       "         -2.57294208e-01,  2.37895817e-01,  7.93751478e-02,\n",
       "          8.24106038e-02, -1.57486618e-01, -1.52681768e-02,\n",
       "          2.78152972e-01],\n",
       "        [-2.66723335e-01,  2.41590947e-01, -9.45264250e-02,\n",
       "          1.60042018e-01,  2.16368526e-01,  1.01584792e-01,\n",
       "         -1.66403294e-01,  6.34652078e-02, -2.50389218e-01,\n",
       "          2.42061168e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_first_layer (Dense)      (None, 64)                256       \n",
      "                                                                 \n",
      " my_last_layer (Dense)       (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3, )))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256 (1.00 KB)\n",
      "Trainable params: 256 (1.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 64)                256       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 906 (3.54 KB)\n",
      "Trainable params: 906 (3.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
