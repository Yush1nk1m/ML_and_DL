{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "class Vectorizer:\n",
    "    def standardize(self, text):\n",
    "        text = text.lower()\n",
    "        return \"\".join(char for char in text\n",
    "                       if char not in string.punctuation)\n",
    "        \n",
    "    def tokenize(self, text):\n",
    "        return text.split()\n",
    "    \n",
    "    def make_vocabulary(self, dataset):\n",
    "        self.vocabulary = { \"\": 0, \"[UNK]\": 1 }\n",
    "        for text in dataset:\n",
    "            text = self.standardize(text)\n",
    "            tokens = self.tokenize(text)\n",
    "            for token in tokens:\n",
    "                if token not in self.vocabulary:\n",
    "                    self.vocabulary[token] = len(self.vocabulary)\n",
    "        self.inverse_vocabulary = dict(\n",
    "            (v, k) for k, v in self.vocabulary.items()\n",
    "        )\n",
    "    \n",
    "    def encode(self, text):\n",
    "        text = self.standardize(text)\n",
    "        tokens = self.tokenize(text)\n",
    "        return [self.vocabulary.get(token, 1) for token in tokens]\n",
    "    \n",
    "    def decode(self, int_sequence):\n",
    "        return \" \".join(\n",
    "            self.inverse_vocabulary.get(i, \"[UNK]\") for i in int_sequence\n",
    "        )\n",
    "\n",
    "vectorizer = Vectorizer()\n",
    "dataset = [\n",
    "    \"I write, erase, rewrite\",\n",
    "    \"Erase again, and then\",\n",
    "    \"A poppy blooms.\",\n",
    "]\n",
    "vectorizer.make_vocabulary(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 5, 7, 1, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sequence = vectorizer.encode(test_sentence)\n",
    "print(encoded_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "source": [
    "decoded_sentence = vectorizer.decode(encoded_sequence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 22:21:53.719048: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-15 22:21:53.756995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-15 22:21:53.757030: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-15 22:21:53.757920: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-15 22:21:53.764043: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-15 22:21:54.566329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-15 22:21:55.271364: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.361924: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.362136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.362970: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.363074: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.363160: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.428027: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.428211: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.428332: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-15 22:21:55.428418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10400 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:03:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "text_vectorization = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "def custom_standardization_fn(string_tensor):\n",
    "    lowercase_string = tf.strings.lower(string_tensor)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "def custom_split_fn(string_tensor):\n",
    "    return tf.strings.split(string_tensor)\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    standardize=custom_standardization_fn,\n",
    "    split=custom_split_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    \"I write, erase, rewrite\",\n",
    "    \"Erase again, and then\",\n",
    "    \"A poppy blooms.\",\n",
    "]\n",
    "text_vectorization.adapt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'erase',\n",
       " 'write',\n",
       " 'then',\n",
       " 'rewrite',\n",
       " 'poppy',\n",
       " 'i',\n",
       " 'blooms',\n",
       " 'and',\n",
       " 'again',\n",
       " 'a']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorization.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 7  3  5  9  1  5 10], shape=(7,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "vocabulary = text_vectorization.get_vocabulary()\n",
    "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
    "encoded_sentence = text_vectorization(test_sentence)\n",
    "print(encoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i write rewrite and [UNK] rewrite again\n"
     ]
    }
   ],
   "source": [
    "inverse_vocabulary = dict(enumerate(vocabulary))\n",
    "decoded_sentence = \" \".join(inverse_vocabulary[int(i)] for i in encoded_sentence)\n",
    "print(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      " 17 80.2M   17 13.7M    0     0   143k      0  0:09:30  0:01:37  0:07:53     0:07:34  0:00:54  0:06:40  201k^C\n",
      "\n",
      "gzip: stdin: unexpected end of file\n",
      "tar: 아카이브에 예기치 않은 파일 끝 문자\n",
      "tar: 아카이브에 예기치 않은 파일 끝 문자\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n",
    "!rm -f aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "!cat aclImdb/train/pos/4077_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b\"I would love to have that two hours of my life back. It seemed to be several clips from Steve's Animal Planet series that was spliced into a loosely constructed script. Don't Go, If you must see it, wait for the video ...\", shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"multi_hot\",\n",
    ")\n",
    "\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_1gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "binary_1gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "binary_1gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'float32'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1. 1. 1. ... 0. 0. 0.], shape=(20000,), dtype=float32)\n",
      "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in binary_1gram_train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def get_model(max_tokens=20000, hidden_dim=16):\n",
    "    inputs = keras.Input(shape=(max_tokens, ))\n",
    "    x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=\"rmsprop\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 4s 5ms/step - loss: 0.4151 - accuracy: 0.8242 - val_loss: 0.2836 - val_accuracy: 0.8872\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2745 - accuracy: 0.8980 - val_loss: 0.2692 - val_accuracy: 0.8924\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2386 - accuracy: 0.9170 - val_loss: 0.2790 - val_accuracy: 0.8984\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2247 - accuracy: 0.9231 - val_loss: 0.2968 - val_accuracy: 0.8940\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2174 - accuracy: 0.9288 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2107 - accuracy: 0.9319 - val_loss: 0.3139 - val_accuracy: 0.8920\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2080 - accuracy: 0.9359 - val_loss: 0.3260 - val_accuracy: 0.8924\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2021 - accuracy: 0.9392 - val_loss: 0.3390 - val_accuracy: 0.8902\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2031 - accuracy: 0.9383 - val_loss: 0.3421 - val_accuracy: 0.8826\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2011 - accuracy: 0.9381 - val_loss: 0.3641 - val_accuracy: 0.8884\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.8878\n",
      "테스트 정확도: 0.888\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True)\n",
    "]\n",
    "model.fit(\n",
    "    binary_1gram_train_ds.cache(),\n",
    "    epochs=10,\n",
    "    validation_data=binary_1gram_val_ds.cache(),\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model = keras.models.load_model(\"binary_1gram.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"multi_hot\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.3728 - accuracy: 0.8464 - val_loss: 0.2629 - val_accuracy: 0.8954\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2331 - accuracy: 0.9166 - val_loss: 0.2607 - val_accuracy: 0.9002\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2029 - accuracy: 0.9354 - val_loss: 0.2767 - val_accuracy: 0.9010\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1805 - accuracy: 0.9431 - val_loss: 0.2932 - val_accuracy: 0.8990\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1717 - accuracy: 0.9481 - val_loss: 0.3088 - val_accuracy: 0.8974\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1640 - accuracy: 0.9522 - val_loss: 0.3310 - val_accuracy: 0.8964\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1647 - accuracy: 0.9528 - val_loss: 0.3367 - val_accuracy: 0.8966\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1578 - accuracy: 0.9566 - val_loss: 0.3502 - val_accuracy: 0.8954\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1577 - accuracy: 0.9583 - val_loss: 0.3558 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.1460 - accuracy: 0.9603 - val_loss: 0.3747 - val_accuracy: 0.8952\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.2684 - accuracy: 0.9002\n",
      "테스트 정확도: 0.900\n"
     ]
    }
   ],
   "source": [
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "binary_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "binary_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "binary_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    binary_2gram_train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=binary_2gram_val_ds,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(\"binary_2gram.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"count\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorization = TextVectorization(\n",
    "    ngrams=2,\n",
    "    max_tokens=20000,\n",
    "    output_mode=\"tf_idf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 20000)]           0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                320016    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 320033 (1.22 MB)\n",
      "Trainable params: 320033 (1.22 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.4881 - accuracy: 0.7934 - val_loss: 0.3055 - val_accuracy: 0.8756\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.3183 - accuracy: 0.8686 - val_loss: 0.3216 - val_accuracy: 0.8794\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2884 - accuracy: 0.8816 - val_loss: 0.3091 - val_accuracy: 0.8928\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2658 - accuracy: 0.8891 - val_loss: 0.3368 - val_accuracy: 0.8928\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2460 - accuracy: 0.8989 - val_loss: 0.3480 - val_accuracy: 0.8830\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2356 - accuracy: 0.8993 - val_loss: 0.3480 - val_accuracy: 0.8820\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2355 - accuracy: 0.9011 - val_loss: 0.3650 - val_accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.2073 - accuracy: 0.9089 - val_loss: 0.3839 - val_accuracy: 0.8742\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.2121 - accuracy: 0.9084 - val_loss: 0.3659 - val_accuracy: 0.8816\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.2124 - accuracy: 0.9054 - val_loss: 0.3812 - val_accuracy: 0.8820\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3057 - accuracy: 0.8816\n",
      "테스트 정확도: 0.882\n"
     ]
    }
   ],
   "source": [
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "tfidf_2gram_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "tfidf_2gram_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "tfidf_2gram_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "\n",
    "model = get_model()\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    tfidf_2gram_train_ds,\n",
    "    epochs=10,\n",
    "    validation_data=tfidf_2gram_val_ds,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling layer 'string_lookup_1' (type StringLookup).\n\nWhen using `output_mode=tf_idf` and `pad_to_max_tokens=False`, you must set the layer's vocabulary before calling it. Either pass a `vocabulary` argument to the layer, or call `adapt` with some sample data.\n\nCall arguments received by layer 'string_lookup_1' (type StringLookup):\n  • inputs=tf.RaggedTensor(values=Tensor(\"text_vectorization_1/StringNGrams/StringNGrams:0\", shape=(None,), dtype=string), row_splits=Tensor(\"text_vectorization_1/StringNGrams/StringNGrams:1\", shape=(None,), dtype=int64))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, ), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtext_vectorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(processed_inputs)\n\u001b[1;32m      4\u001b[0m inference_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mModel(inputs, outputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/layers/preprocessing/index_lookup.py:926\u001b[0m, in \u001b[0;36mIndexLookup._ensure_known_vocab_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frozen_vocab_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 926\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    927\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen using `output_mode=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    928\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand `pad_to_max_tokens=False`, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    929\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must set the layer\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms vocabulary before calling it. Either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    930\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a `vocabulary` argument to the layer, or call `adapt` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith some sample data.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_mode)\n\u001b[1;32m    932\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exception encountered when calling layer 'string_lookup_1' (type StringLookup).\n\nWhen using `output_mode=tf_idf` and `pad_to_max_tokens=False`, you must set the layer's vocabulary before calling it. Either pass a `vocabulary` argument to the layer, or call `adapt` with some sample data.\n\nCall arguments received by layer 'string_lookup_1' (type StringLookup):\n  • inputs=tf.RaggedTensor(values=Tensor(\"text_vectorization_1/StringNGrams/StringNGrams:0\", shape=(None,), dtype=string), row_splits=Tensor(\"text_vectorization_1/StringNGrams/StringNGrams:1\", shape=(None,), dtype=int64))"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(1, ), dtype=\"string\")\n",
    "processed_inputs = text_vectorization(inputs)\n",
    "outputs = model(processed_inputs)\n",
    "inference_model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inference_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m raw_text_data \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor([\n\u001b[1;32m      4\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThat was an excellent movie, I loved it.\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      5\u001b[0m ])\n\u001b[0;32m----> 6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43minference_model\u001b[49m(raw_text_data)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m긍정적인 리뷰일 확률: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mfloat\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inference_model' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "raw_text_data = tf.convert_to_tensor([\n",
    "    [\"That was an excellent movie, I loved it.\"],\n",
    "])\n",
    "predictions = inference_model(raw_text_data)\n",
    "print(f\"긍정적인 리뷰일 확률: {float(predictions[0] * 100):.2f}%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")\n",
    "int_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " tf.one_hot_1 (TFOpLambda)   (None, None, 20000)       0         \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 64)                5128448   \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5128513 (19.56 MB)\n",
      "Trainable params: 5128513 (19.56 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 22:22:56.652434: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-02-15 22:22:57.736422: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fa9641b3e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-15 22:22:57.736451: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2024-02-15 22:22:57.744293: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1708003377.808500   56078 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 114s 177ms/step - loss: 0.5594 - accuracy: 0.7156 - val_loss: 0.3928 - val_accuracy: 0.8550\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.3679 - accuracy: 0.8605 - val_loss: 0.3176 - val_accuracy: 0.8742\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 110s 177ms/step - loss: 0.3001 - accuracy: 0.8945 - val_loss: 0.3370 - val_accuracy: 0.8776\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 110s 177ms/step - loss: 0.2568 - accuracy: 0.9126 - val_loss: 0.3106 - val_accuracy: 0.8832\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.2256 - accuracy: 0.9255 - val_loss: 0.3234 - val_accuracy: 0.8882\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.1969 - accuracy: 0.9348 - val_loss: 0.3165 - val_accuracy: 0.8678\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.1729 - accuracy: 0.9445 - val_loss: 0.3729 - val_accuracy: 0.8648\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.1486 - accuracy: 0.9538 - val_loss: 0.3465 - val_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.1287 - accuracy: 0.9608 - val_loss: 0.5675 - val_accuracy: 0.8794\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 110s 176ms/step - loss: 0.1037 - accuracy: 0.9700 - val_loss: 0.4341 - val_accuracy: 0.8820\n",
      "782/782 [==============================] - 80s 101ms/step - loss: 0.3297 - accuracy: 0.8774\n",
      "테스트 정확도: 0.877\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    int_train_ds,\n",
    "    validation_data=int_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirecti  (None, 64)                73984     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5194049 (19.81 MB)\n",
      "Trainable params: 5194049 (19.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 43s 65ms/step - loss: 0.5375 - accuracy: 0.7312 - val_loss: 0.4580 - val_accuracy: 0.8298\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.3719 - accuracy: 0.8587 - val_loss: 0.5169 - val_accuracy: 0.8004\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.2938 - accuracy: 0.8938 - val_loss: 0.3227 - val_accuracy: 0.8806\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.2460 - accuracy: 0.9138 - val_loss: 0.7987 - val_accuracy: 0.7744\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.2105 - accuracy: 0.9276 - val_loss: 0.3518 - val_accuracy: 0.8752\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 21s 34ms/step - loss: 0.1853 - accuracy: 0.9373 - val_loss: 0.3802 - val_accuracy: 0.8708\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 21s 33ms/step - loss: 0.1570 - accuracy: 0.9491 - val_loss: 0.4400 - val_accuracy: 0.8722\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.1379 - accuracy: 0.9570 - val_loss: 0.4210 - val_accuracy: 0.8566\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 26s 41ms/step - loss: 0.1169 - accuracy: 0.9633 - val_loss: 0.6196 - val_accuracy: 0.8538\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.1134 - accuracy: 0.9654 - val_loss: 0.5077 - val_accuracy: 0.8664\n",
      "782/782 [==============================] - 12s 13ms/step - loss: 0.3383 - accuracy: 0.8722\n",
      "테스트 정확도: 0.872\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    int_train_ds,\n",
    "    validation_data=int_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(\"embeddings_bidir_lstm.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ True  True  True  True False False False]\n",
      " [ True  True  True  True  True False False]\n",
      " [ True  True False False False False False]], shape=(3, 7), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = layers.Embedding(input_dim=10, output_dim=256, mask_zero=True)\n",
    "some_input = [\n",
    "    [4, 3, 2, 1, 0, 0, 0],\n",
    "    [5, 4, 3, 2, 1, 0, 0],\n",
    "    [2, 1, 0, 0, 0, 0, 0]\n",
    "]\n",
    "mask = embedding_layer.compute_mask(some_input)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirecti  (None, 64)                73984     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5194049 (19.81 MB)\n",
      "Trainable params: 5194049 (19.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-15 23:29:25.605095: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_36/output/_23'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 49s 71ms/step - loss: 0.4402 - accuracy: 0.7913 - val_loss: 0.3423 - val_accuracy: 0.8382\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 30s 48ms/step - loss: 0.2775 - accuracy: 0.8906 - val_loss: 0.2907 - val_accuracy: 0.8818\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 27s 44ms/step - loss: 0.2177 - accuracy: 0.9179 - val_loss: 0.3116 - val_accuracy: 0.8708\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 28s 45ms/step - loss: 0.1656 - accuracy: 0.9397 - val_loss: 0.3124 - val_accuracy: 0.8810\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.1277 - accuracy: 0.9548 - val_loss: 0.3718 - val_accuracy: 0.8804\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.0977 - accuracy: 0.9665 - val_loss: 0.3955 - val_accuracy: 0.8764\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 22s 35ms/step - loss: 0.0755 - accuracy: 0.9757 - val_loss: 0.4743 - val_accuracy: 0.8698\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 22s 34ms/step - loss: 0.0609 - accuracy: 0.9797 - val_loss: 0.4612 - val_accuracy: 0.8770\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 23s 36ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.5034 - val_accuracy: 0.8678\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.0420 - accuracy: 0.9867 - val_loss: 0.6515 - val_accuracy: 0.8546\n",
      "782/782 [==============================] - 17s 19ms/step - loss: 0.3024 - accuracy: 0.8735\n",
      "테스트 정확도: 0.874\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(None, ), dtype=\"int64\")\n",
    "embedded = layers.Embedding(\n",
    "    input_dim=max_tokens,\n",
    "    output_dim=256,\n",
    "    mask_zero=True,\n",
    ")(inputs)\n",
    "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_lstm_with_masking.keras\",\n",
    "                                    save_best_only=True)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    int_train_ds,\n",
    "    validation_data=int_val_ds,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "model = keras.models.load_model(\"embeddings_bidir_lstm_with_masking.keras\")\n",
    "print(f\"테스트 정확도: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-15 23:40:55--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "nlp.stanford.edu (nlp.stanford.edu) 해석 중... 171.64.67.140\n",
      "다음으로 연결 중: nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 302 Found\n",
      "위치: https://nlp.stanford.edu/data/glove.6B.zip [따라감]\n",
      "--2024-02-15 23:40:55--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "다음으로 연결 중: nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 301 Moved Permanently\n",
      "위치: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [따라감]\n",
      "--2024-02-15 23:40:56--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "downloads.cs.stanford.edu (downloads.cs.stanford.edu) 해석 중... 171.64.64.22\n",
      "다음으로 연결 중: downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... 연결했습니다.\n",
      "HTTP 요청을 보냈습니다. 응답 기다리는 중... 200 OK\n",
      "길이: 862182613 (822M) [application/zip]\n",
      "저장 위치: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.10MB/s    / 2m 46s   \n",
      "\n",
      "2024-02-15 23:43:43 (4.95 MB/s) - ‘glove.6B.zip’ 저장함 [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip\n",
    "!rm -f glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 벡터 개수: 400000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path_to_glove_file = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(f\"단어 벡터 개수: {len(embeddings_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
